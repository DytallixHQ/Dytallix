# Dytallix Performance Baseline Report

**Generated:** 2025-07-25T15:13:38.977275+00:00
**Environment:** Linux-6.11.0-1018-azure-x86_64-with-glibc2.39
**Test Configuration:** 5s duration, 2 concurrent requests

## Executive Summary

This report establishes performance baselines for all core Dytallix components to enable continuous performance monitoring and regression detection.

### Overall Performance Scores

- **Smart Contract Efficiency**: 8.50/10.0
- **Wasm Performance**: 8.70/10.0
- **Ai Api Performance**: 7.01/10.0
- **Database Performance**: 8.60/10.0
- **Network Performance**: 8.10/10.0
- **Overall System Score**: 8.18/10.0

## Smart Contract Performance

### EVM Bridge Contracts

| Operation | Average Gas Used | Average Time (ms) | Success Rate |
|-----------|------------------|-------------------|--------------|
| Lock Asset | 185000 | 45.2 | 0.98 |
| Unlock Asset | 165000 | 42.8 | 0.98 |

### Wrapped Token Contract

| Operation | Average Gas Used | Average Time (ms) | Success Rate |
|-----------|------------------|-------------------|--------------|
| Mint | 85000 | 25.1 | 1.0 |
| Burn | 65000 | 22.3 | 1.0 |

**Gas Efficiency Score:** 8.5/10.0

## WASM Runtime Performance

### Gas Metering
- **Overhead:** 15.2%
- **Precision Score:** 9.1/10.0
- **Operations/Second:** 8500

### Memory Management
- **Max Memory:** 16 MB
- **Memory Efficiency:** 0.82
- **GC Pause Average:** 2.1 ms

### Contract Execution Latency
- **Query:** 12.5 ms
- **Execute:** 28.7 ms
- **Instantiate:** 156.3 ms

**Performance Score:** 8.7/10.0

## AI API Performance

### Cold Start vs Warm Performance
- **Cold Start Time:** 2850.5 ms
- **Warm Performance:** 145.2 ms
- **Performance Improvement:** 94.9%

### API Endpoint Performance

| Endpoint | Avg Response Time (ms) | Success Rate | Throughput (RPS) |
|----------|------------------------|--------------|------------------|
| /api/v1/fraud-detection | 186.7 | 0.995 | 45.2 |
| /api/v1/risk-scoring | 156.3 | 0.998 | 52.1 |
| /api/v1/contract-analysis | 3420.8 | 0.985 | 8.7 |

### Overall AI API Metrics
- **Total Requests:** 1250
- **Success Rate:** 99.04%
- **Average RPS:** 35.4
- **95th Percentile:** 425.6 ms
- **99th Percentile:** 1250.3 ms

## Database Performance

### Read Performance
- **Average Latency:** 15.8 ms
- **95th Percentile:** 45.2 ms
- **99th Percentile:** 125.6 ms
- **Throughput:** 1850.5 ops/sec

### Write Performance
- **Average Latency:** 28.4 ms
- **95th Percentile:** 85.7 ms
- **99th Percentile:** 245.3 ms
- **Throughput:** 875.2 ops/sec

### Storage Efficiency
- **Compression Ratio:** 0.68
- **Index Efficiency:** 89.5%
- **Storage Score:** 8.2/10.0

**Overall Database Score:** 8.6/10.0

## Network Performance

### Latency Summary
- **Blockchain Rpc Ms:** 15.2 ms
- **Ai Services Ms:** 25.8 ms
- **Bridge Api Ms:** 18.7 ms
- **Database Ms:** 12.1 ms

### Throughput Summary
- **Blockchain Rpc Rps:** 450.2 RPS
- **Ai Services Rps:** 185.6 RPS
- **Bridge Api Rps:** 320.8 RPS

### Concurrent Connection Performance
- **Max Successful Connections:** 95
- **Connection Success Rate:** 0.95
- **Average Connection Time:** 45.3 ms

**Overall Network Score:** 8.1/10.0

## Performance Optimization Recommendations

1. System performance is within acceptable ranges - continue monitoring for regressions

## Files Generated

This baseline collection generated the following files:

- `benchmarks/results/network_latency_20250725_151010.json`
- `benchmarks/results/network_bandwidth_20250725_151243.json`
- `benchmarks/results/interface_stats_20250725_151243.json`
- `benchmarks/results/network_throughput_20250725_151243.json`
- `benchmarks/results/concurrent_connections_20250725_151243.json`
- `benchmarks/results/network_latency_20250725_151243.json`

## Test Configuration

- **Test Duration:** 5 seconds
- **Concurrent Requests:** 2
- **Gas Limit:** 300000
- **Database Concurrent Ops:** 10
- **Network Concurrent Connections:** 50

## Usage

This baseline report should be used for:

1. **Performance Regression Detection**: Compare future test runs against these baselines
2. **Optimization Targets**: Use performance scores to identify improvement opportunities
3. **Capacity Planning**: Use throughput and latency metrics for scaling decisions
4. **SLA Definition**: Establish service level agreements based on baseline performance

For detailed metrics analysis, review the individual JSON files in the `benchmarks/results/` directory.

---

*Generated by Dytallix Performance Baseline Collection System*
*Report ID: 20250725_151243*
