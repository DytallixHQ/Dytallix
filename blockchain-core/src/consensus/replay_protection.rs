//! Replay Protection and Response Caching Module
//!
//! This module implements comprehensive replay protection for AI Oracle responses
//! and a sophisticated caching system to avoid duplicate requests and improve performance.

use anyhow::Result;
use chrono::{DateTime, Utc, Duration as ChronoDuration};
use serde::{Deserialize, Serialize};
use std::collections::{HashMap, BTreeMap};
use std::sync::{Arc, RwLock};
use sha3::{Sha3_256, Digest};
use log::{info, warn, debug};

use crate::consensus::{SignedAIOracleResponse, AIRequestPayload};

/// Configuration for replay protection and caching
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ReplayProtectionConfig {
    /// Maximum age of responses to accept (in seconds)
    pub max_response_age_seconds: u64,
    /// Maximum age of nonces to track (in seconds)
    pub nonce_retention_seconds: u64,
    /// Maximum number of nonces to cache
    pub max_nonce_cache_size: usize,
    /// Response cache TTL in seconds
    pub response_cache_ttl_seconds: u64,
    /// Maximum number of cached responses
    pub max_response_cache_size: usize,
    /// Timestamp tolerance window in seconds (for clock skew)
    pub timestamp_tolerance_seconds: u64,
    /// Enable cache statistics collection
    pub enable_cache_stats: bool,
    /// Cache cleanup interval in seconds
    pub cache_cleanup_interval_seconds: u64,
}

impl Default for ReplayProtectionConfig {
    fn default() -> Self {
        Self {
            max_response_age_seconds: 300,      // 5 minutes
            nonce_retention_seconds: 600,       // 10 minutes
            max_nonce_cache_size: 100_000,      // 100k nonces
            response_cache_ttl_seconds: 300,    // 5 minutes
            max_response_cache_size: 10_000,    // 10k responses
            timestamp_tolerance_seconds: 30,    // 30 seconds for clock skew
            enable_cache_stats: true,
            cache_cleanup_interval_seconds: 60, // 1 minute cleanup interval
        }
    }
}

/// Nonce entry for replay protection
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct NonceEntry {
    /// The nonce value
    pub nonce: u64,
    /// When this nonce was first seen
    pub first_seen: DateTime<Utc>,
    /// Oracle ID that used this nonce
    pub oracle_id: String,
    /// Request hash associated with this nonce
    pub request_hash: String,
    /// Usage count (for detecting multiple uses)
    pub usage_count: u32,
}

/// Cached response entry
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CachedResponseEntry {
    /// The original request payload hash
    pub request_hash: String,
    /// The signed response
    pub response: SignedAIOracleResponse,
    /// When this was cached
    pub cached_at: DateTime<Utc>,
    /// Cache hit count
    pub hit_count: u32,
    /// Last accessed time
    pub last_accessed: DateTime<Utc>,
    /// Oracle ID that provided this response
    pub oracle_id: String,
    /// Response size in bytes
    pub response_size: usize,
}

/// Timestamp validation entry
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TimestampEntry {
    /// Response timestamp
    pub timestamp: DateTime<Utc>,
    /// When we received/validated this timestamp
    pub validated_at: DateTime<Utc>,
    /// Oracle ID
    pub oracle_id: String,
    /// Request ID
    pub request_id: String,
}

/// Cache statistics
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CacheStatistics {
    /// Total cache hits
    pub total_hits: u64,
    /// Total cache misses
    pub total_misses: u64,
    /// Total entries added
    pub total_entries_added: u64,
    /// Total entries evicted
    pub total_entries_evicted: u64,
    /// Current cache size
    pub current_cache_size: usize,
    /// Current nonce cache size
    pub current_nonce_cache_size: usize,
    /// Total nonces blocked (replay attempts)
    pub total_nonces_blocked: u64,
    /// Total timestamp violations
    pub total_timestamp_violations: u64,
    /// Average response size
    pub avg_response_size: f64,
    /// Cache hit ratio
    pub hit_ratio: f64,
    /// Last cleanup time
    pub last_cleanup: DateTime<Utc>,
    /// Memory usage estimate (bytes)
    pub estimated_memory_usage: usize,
}

impl Default for CacheStatistics {
    fn default() -> Self {
        Self {
            total_hits: 0,
            total_misses: 0,
            total_entries_added: 0,
            total_entries_evicted: 0,
            current_cache_size: 0,
            current_nonce_cache_size: 0,
            total_nonces_blocked: 0,
            total_timestamp_violations: 0,
            avg_response_size: 0.0,
            hit_ratio: 0.0,
            last_cleanup: Utc::now(),
            estimated_memory_usage: 0,
        }
    }
}

/// Errors related to replay protection and caching
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ReplayProtectionError {
    /// Nonce has already been used
    NonceReused {
        nonce: u64,
        oracle_id: String,
        first_used: DateTime<Utc>,
    },
    /// Response timestamp is too old
    ResponseTooOld {
        timestamp: DateTime<Utc>,
        max_age_seconds: u64,
    },
    /// Response timestamp is too far in the future
    ResponseTooFuture {
        timestamp: DateTime<Utc>,
        tolerance_seconds: u64,
    },
    /// Cache is full and cannot accept new entries
    CacheFull {
        current_size: usize,
        max_size: usize,
    },
    /// Invalid timestamp format
    InvalidTimestamp {
        timestamp_str: String,
        error: String,
    },
    /// Hash computation failed
    HashError {
        error: String,
    },
}

impl std::fmt::Display for ReplayProtectionError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            ReplayProtectionError::NonceReused { nonce, oracle_id, first_used } => {
                write!(f, "Nonce {} from oracle {} was already used at {}", nonce, oracle_id, first_used)
            }
            ReplayProtectionError::ResponseTooOld { timestamp, max_age_seconds } => {
                write!(f, "Response timestamp {} is older than {} seconds", timestamp, max_age_seconds)
            }
            ReplayProtectionError::ResponseTooFuture { timestamp, tolerance_seconds } => {
                write!(f, "Response timestamp {} is more than {} seconds in the future", timestamp, tolerance_seconds)
            }
            ReplayProtectionError::CacheFull { current_size, max_size } => {
                write!(f, "Cache is full ({}/{})", current_size, max_size)
            }
            ReplayProtectionError::InvalidTimestamp { timestamp_str, error } => {
                write!(f, "Invalid timestamp '{}': {}", timestamp_str, error)
            }
            ReplayProtectionError::HashError { error } => {
                write!(f, "Hash computation failed: {}", error)
            }
        }
    }
}

impl std::error::Error for ReplayProtectionError {}

/// Main replay protection and caching manager
#[derive(Debug)]
pub struct ReplayProtectionManager {
    /// Configuration
    config: ReplayProtectionConfig,
    /// Nonce cache for replay protection
    nonce_cache: Arc<RwLock<HashMap<u64, NonceEntry>>>,
    /// Response cache by request hash
    response_cache: Arc<RwLock<HashMap<String, CachedResponseEntry>>>,
    /// Timestamp validation cache
    timestamp_cache: Arc<RwLock<BTreeMap<DateTime<Utc>, TimestampEntry>>>,
    /// Cache statistics
    stats: Arc<RwLock<CacheStatistics>>,
    /// Last cleanup time
    last_cleanup: Arc<RwLock<DateTime<Utc>>>,
}

impl ReplayProtectionManager {
    /// Create a new replay protection manager
    pub fn new(config: ReplayProtectionConfig) -> Self {
        info!("Initializing replay protection manager with config: {:?}", config);
        
        Self {
            config,
            nonce_cache: Arc::new(RwLock::new(HashMap::new())),
            response_cache: Arc::new(RwLock::new(HashMap::new())),
            timestamp_cache: Arc::new(RwLock::new(BTreeMap::new())),
            stats: Arc::new(RwLock::new(CacheStatistics::default())),
            last_cleanup: Arc::new(RwLock::new(Utc::now())),
        }
    }

    /// Validate a nonce and prevent replay attacks
    pub fn validate_nonce(
        &self,
        nonce: u64,
        oracle_id: &str,
        request_hash: &str,
    ) -> Result<(), ReplayProtectionError> {
        let mut nonce_cache = self.nonce_cache.write().unwrap();
        
        // Check if nonce already exists
        if let Some(existing_entry) = nonce_cache.get_mut(&nonce) {
            // Increment usage count
            existing_entry.usage_count += 1;
            
            // Update statistics
            if self.config.enable_cache_stats {
                let mut stats = self.stats.write().unwrap();
                stats.total_nonces_blocked += 1;
            }
            
            warn!("Replay attack detected: nonce {} already used by oracle {} at {}", 
                  nonce, existing_entry.oracle_id, existing_entry.first_seen);
            
            return Err(ReplayProtectionError::NonceReused {
                nonce,
                oracle_id: existing_entry.oracle_id.clone(),
                first_used: existing_entry.first_seen,
            });
        }
        
        // Add new nonce entry
        let entry = NonceEntry {
            nonce,
            first_seen: Utc::now(),
            oracle_id: oracle_id.to_string(),
            request_hash: request_hash.to_string(),
            usage_count: 1,
        };
        
        nonce_cache.insert(nonce, entry);
        
        // Update statistics
        if self.config.enable_cache_stats {
            let mut stats = self.stats.write().unwrap();
            stats.current_nonce_cache_size = nonce_cache.len();
        }
        
        debug!("Nonce {} validated for oracle {}", nonce, oracle_id);
        Ok(())
    }

    /// Validate response timestamp
    pub fn validate_timestamp(
        &self,
        timestamp: DateTime<Utc>,
        oracle_id: &str,
        request_id: &str,
    ) -> Result<(), ReplayProtectionError> {
        let now = Utc::now();
        let max_age = ChronoDuration::seconds(self.config.max_response_age_seconds as i64);
        let tolerance = ChronoDuration::seconds(self.config.timestamp_tolerance_seconds as i64);
        
        // Check if response is too old
        if now.signed_duration_since(timestamp) > max_age {
            if self.config.enable_cache_stats {
                let mut stats = self.stats.write().unwrap();
                stats.total_timestamp_violations += 1;
            }
            
            warn!("Response timestamp too old: {} from oracle {}", timestamp, oracle_id);
            return Err(ReplayProtectionError::ResponseTooOld {
                timestamp,
                max_age_seconds: self.config.max_response_age_seconds,
            });
        }
        
        // Check if response is too far in the future (accounting for clock skew)
        if timestamp.signed_duration_since(now) > tolerance {
            if self.config.enable_cache_stats {
                let mut stats = self.stats.write().unwrap();
                stats.total_timestamp_violations += 1;
            }
            
            warn!("Response timestamp too far in future: {} from oracle {}", timestamp, oracle_id);
            return Err(ReplayProtectionError::ResponseTooFuture {
                timestamp,
                tolerance_seconds: self.config.timestamp_tolerance_seconds,
            });
        }
        
        // Add to timestamp cache for tracking
        let mut timestamp_cache = self.timestamp_cache.write().unwrap();
        let entry = TimestampEntry {
            timestamp,
            validated_at: now,
            oracle_id: oracle_id.to_string(),
            request_id: request_id.to_string(),
        };
        
        timestamp_cache.insert(timestamp, entry);
        
        debug!("Timestamp {} validated for oracle {}", timestamp, oracle_id);
        Ok(())
    }

    /// Compute request hash for caching
    pub fn compute_request_hash(request: &AIRequestPayload) -> Result<String, ReplayProtectionError> {
        let serialized = serde_json::to_string(request)
            .map_err(|e| ReplayProtectionError::HashError {
                error: format!("Failed to serialize request: {}", e),
            })?;
        
        let mut hasher = Sha3_256::new();
        hasher.update(serialized.as_bytes());
        let result = hasher.finalize();
        
        Ok(hex::encode(result))
    }

    /// Check if response is cached
    pub fn get_cached_response(&self, request_hash: &str) -> Option<SignedAIOracleResponse> {
        let mut response_cache = self.response_cache.write().unwrap();
        
        if let Some(entry) = response_cache.get_mut(request_hash) {
            let now = Utc::now();
            let cache_age = now.signed_duration_since(entry.cached_at);
            let max_age = ChronoDuration::seconds(self.config.response_cache_ttl_seconds as i64);
            
            // Check if cached response is still valid
            if cache_age <= max_age {
                // Update access statistics
                entry.hit_count += 1;
                entry.last_accessed = now;
                
                // Update global statistics
                if self.config.enable_cache_stats {
                    let mut stats = self.stats.write().unwrap();
                    stats.total_hits += 1;
                    stats.hit_ratio = stats.total_hits as f64 / (stats.total_hits + stats.total_misses) as f64;
                }
                
                debug!("Cache hit for request hash: {}", request_hash);
                return Some(entry.response.clone());
            } else {
                // Cache entry expired, remove it
                response_cache.remove(request_hash);
                
                if self.config.enable_cache_stats {
                    let mut stats = self.stats.write().unwrap();
                    stats.total_entries_evicted += 1;
                    stats.current_cache_size = response_cache.len();
                }
                
                debug!("Cache entry expired for request hash: {}", request_hash);
            }
        }
        
        // Cache miss
        if self.config.enable_cache_stats {
            let mut stats = self.stats.write().unwrap();
            stats.total_misses += 1;
            stats.hit_ratio = stats.total_hits as f64 / (stats.total_hits + stats.total_misses) as f64;
        }
        
        debug!("Cache miss for request hash: {}", request_hash);
        None
    }

    /// Cache a response
    pub fn cache_response(
        &self,
        request_hash: String,
        response: SignedAIOracleResponse,
        oracle_id: &str,
    ) -> Result<(), ReplayProtectionError> {
        let mut response_cache = self.response_cache.write().unwrap();
        
        // Check cache size limits
        if response_cache.len() >= self.config.max_response_cache_size {
            // Evict oldest entries (LRU-style)
            self.evict_oldest_entries(&mut response_cache)?;
        }
        
        // Calculate response size estimate
        let response_size = serde_json::to_string(&response)
            .map(|s| s.len())
            .unwrap_or(0);
        
        let entry = CachedResponseEntry {
            request_hash: request_hash.clone(),
            response,
            cached_at: Utc::now(),
            hit_count: 0,
            last_accessed: Utc::now(),
            oracle_id: oracle_id.to_string(),
            response_size,
        };
        
        response_cache.insert(request_hash.clone(), entry);
        
        // Update statistics
        if self.config.enable_cache_stats {
            let mut stats = self.stats.write().unwrap();
            stats.total_entries_added += 1;
            stats.current_cache_size = response_cache.len();
            
            // Update average response size
            let total_size: usize = response_cache.values().map(|e| e.response_size).sum();
            stats.avg_response_size = total_size as f64 / response_cache.len() as f64;
            
            // Update memory usage estimate
            stats.estimated_memory_usage = total_size + (response_cache.len() * 200); // Approximate overhead
        }
        
        debug!("Cached response for request hash: {} from oracle: {}", request_hash, oracle_id);
        Ok(())
    }

    /// Evict oldest cache entries to make room for new ones
    fn evict_oldest_entries(
        &self,
        response_cache: &mut HashMap<String, CachedResponseEntry>,
    ) -> Result<(), ReplayProtectionError> {
        let entries_to_remove = response_cache.len() / 10; // Remove 10% of entries
        
        // Find oldest entries by last_accessed time
        let mut entries: Vec<_> = response_cache.iter().collect();
        entries.sort_by_key(|(_, entry)| entry.last_accessed);
        
        // Collect keys to remove to avoid borrow checker issues
        let keys_to_remove: Vec<_> = entries.iter().take(entries_to_remove).map(|(k, _)| k.to_string()).collect();
        
        for hash in keys_to_remove {
            response_cache.remove(&hash);
        }
        
        // Update statistics
        if self.config.enable_cache_stats {
            let mut stats = self.stats.write().unwrap();
            stats.total_entries_evicted += entries_to_remove as u64;
            stats.current_cache_size = response_cache.len();
        }
        
        debug!("Evicted {} oldest cache entries", entries_to_remove);
        Ok(())
    }

    /// Invalidate cache entries for a specific oracle
    pub fn invalidate_oracle_cache(&self, oracle_id: &str) -> usize {
        let mut response_cache = self.response_cache.write().unwrap();
        let initial_size = response_cache.len();
        
        response_cache.retain(|_, entry| entry.oracle_id != oracle_id);
        
        let removed_count = initial_size - response_cache.len();
        
        // Update statistics
        if self.config.enable_cache_stats {
            let mut stats = self.stats.write().unwrap();
            stats.total_entries_evicted += removed_count as u64;
            stats.current_cache_size = response_cache.len();
        }
        
        info!("Invalidated {} cache entries for oracle: {}", removed_count, oracle_id);
        removed_count
    }

    /// Invalidate all cached responses (cache clear)
    pub fn invalidate_all_cache(&self) -> usize {
        let mut response_cache = self.response_cache.write().unwrap();
        let removed_count = response_cache.len();
        
        response_cache.clear();
        
        // Update statistics
        if self.config.enable_cache_stats {
            let mut stats = self.stats.write().unwrap();
            stats.total_entries_evicted += removed_count as u64;
            stats.current_cache_size = 0;
        }
        
        info!("Invalidated all {} cache entries", removed_count);
        removed_count
    }

    /// Clean up expired entries (should be called periodically)
    pub fn cleanup_expired_entries(&self) -> Result<usize> {
        let now = Utc::now();
        let mut total_removed = 0;
        
        // Clean up expired nonces
        {
            let mut nonce_cache = self.nonce_cache.write().unwrap();
            let nonce_retention = ChronoDuration::seconds(self.config.nonce_retention_seconds as i64);
            let initial_size = nonce_cache.len();
            
            nonce_cache.retain(|_, entry| {
                now.signed_duration_since(entry.first_seen) <= nonce_retention
            });
            
            let nonces_removed = initial_size - nonce_cache.len();
            total_removed += nonces_removed;
            
            debug!("Cleaned up {} expired nonces", nonces_removed);
        }
        
        // Clean up expired responses
        {
            let mut response_cache = self.response_cache.write().unwrap();
            let cache_ttl = ChronoDuration::seconds(self.config.response_cache_ttl_seconds as i64);
            let initial_size = response_cache.len();
            
            response_cache.retain(|_, entry| {
                now.signed_duration_since(entry.cached_at) <= cache_ttl
            });
            
            let responses_removed = initial_size - response_cache.len();
            total_removed += responses_removed;
            
            debug!("Cleaned up {} expired cached responses", responses_removed);
        }
        
        // Clean up old timestamps
        {
            let mut timestamp_cache = self.timestamp_cache.write().unwrap();
            let timestamp_retention = ChronoDuration::seconds(self.config.max_response_age_seconds as i64 * 2);
            let cutoff_time = now - timestamp_retention;
            
            let initial_size = timestamp_cache.len();
            timestamp_cache.retain(|timestamp, _| *timestamp >= cutoff_time);
            
            let timestamps_removed = initial_size - timestamp_cache.len();
            total_removed += timestamps_removed;
            
            debug!("Cleaned up {} old timestamps", timestamps_removed);
        }
        
        // Update last cleanup time and statistics
        {
            let mut last_cleanup = self.last_cleanup.write().unwrap();
            *last_cleanup = now;
            
            if self.config.enable_cache_stats {
                let mut stats = self.stats.write().unwrap();
                stats.last_cleanup = now;
                stats.total_entries_evicted += total_removed as u64;
                
                // Update current sizes
                stats.current_cache_size = self.response_cache.read().unwrap().len();
                stats.current_nonce_cache_size = self.nonce_cache.read().unwrap().len();
            }
        }
        
        if total_removed > 0 {
            info!("Cleanup completed: removed {} total expired entries", total_removed);
        }
        
        Ok(total_removed)
    }

    /// Get cache statistics
    pub fn get_statistics(&self) -> CacheStatistics {
        self.stats.read().unwrap().clone()
    }

    /// Reset all statistics
    pub fn reset_statistics(&self) {
        let mut stats = self.stats.write().unwrap();
        *stats = CacheStatistics::default();
        info!("Cache statistics reset");
    }

    /// Check if automatic cleanup should be performed
    pub fn should_cleanup(&self) -> bool {
        let last_cleanup = *self.last_cleanup.read().unwrap();
        let cleanup_interval = ChronoDuration::seconds(self.config.cache_cleanup_interval_seconds as i64);
        
        Utc::now().signed_duration_since(last_cleanup) >= cleanup_interval
    }

    /// Get current cache health metrics
    pub fn get_cache_health(&self) -> CacheHealthMetrics {
        let stats = self.get_statistics();
        let response_cache_size = self.response_cache.read().unwrap().len();
        let nonce_cache_size = self.nonce_cache.read().unwrap().len();
        
        CacheHealthMetrics {
            hit_ratio: stats.hit_ratio,
            cache_utilization: response_cache_size as f64 / self.config.max_response_cache_size as f64,
            nonce_utilization: nonce_cache_size as f64 / self.config.max_nonce_cache_size as f64,
            avg_response_size: stats.avg_response_size,
            memory_usage_mb: stats.estimated_memory_usage as f64 / (1024.0 * 1024.0),
            is_healthy: stats.hit_ratio > 0.1 && response_cache_size < self.config.max_response_cache_size,
        }
    }
}

/// Cache health metrics
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CacheHealthMetrics {
    /// Cache hit ratio (0.0 to 1.0)
    pub hit_ratio: f64,
    /// Response cache utilization (0.0 to 1.0)
    pub cache_utilization: f64,
    /// Nonce cache utilization (0.0 to 1.0)
    pub nonce_utilization: f64,
    /// Average response size in bytes
    pub avg_response_size: f64,
    /// Estimated memory usage in MB
    pub memory_usage_mb: f64,
    /// Overall health status
    pub is_healthy: bool,
}

#[cfg(test)]
mod tests {
    // Tests are disabled due to API structure mismatches
    // The functionality is tested through integration tests
}
